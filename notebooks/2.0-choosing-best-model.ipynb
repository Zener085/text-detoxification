{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-04T10:40:29.108897100Z",
     "start_time": "2023-11-04T10:39:51.530535600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timdi\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.data import load_main_dataset, preprocess_dataset\n",
    "from models import gpt35_turbo_model, t5_model, bart_base_model\n",
    "from datasets import load_metric\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset = load_main_dataset()\n",
    "metric = load_metric(\"sacrebleu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T13:04:25.758644Z",
     "start_time": "2023-11-03T13:04:21.404326400Z"
    }
   },
   "id": "3c2d2ff073c5ebb2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def measure(__preds, __labels):\n",
    "    global metric\n",
    "    return metric.compute(predictions=__preds, references=__labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T13:04:25.776066400Z",
     "start_time": "2023-11-03T13:04:25.763936500Z"
    }
   },
   "id": "c4a559c16713f688"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's test GPT3.5. I appologise there are only 10 inputs for the model, but it's not a free stuff and I want to get some number of tries to use the library for me only:)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c102c43da0f3e461"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# GPT3.5\n",
    "test_texts, test_trans = gpt35_turbo_model.preprocess_dataset(dataset)\n",
    "test_texts = test_texts.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T13:07:11.004194300Z",
     "start_time": "2023-11-03T13:07:10.999695100Z"
    }
   },
   "id": "d928096982d9b7f3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'score': 7.1582382262575,\n 'counts': [60, 17, 6, 3],\n 'totals': [178, 168, 158, 148],\n 'precisions': [33.70786516853933,\n  10.119047619047619,\n  3.7974683544303796,\n  2.027027027027027],\n 'bp': 1.0,\n 'sys_len': 178,\n 'ref_len': 150}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = []\n",
    "\n",
    "for i, inp in tqdm(enumerate(test_texts), total=len(test_texts)):\n",
    "    pred.append(gpt35_turbo_model.gpt_detox(test_texts[i]))\n",
    "measure(pred, test_trans)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T13:07:30.238534200Z",
     "start_time": "2023-11-03T13:07:13.694083600Z"
    }
   },
   "id": "e52752249207b91a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now time for t5 model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1049043974c237a8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "t5_input, t5_output = preprocess_dataset(dataset, t5_model.tokenizer, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T10:17:36.661212600Z",
     "start_time": "2023-11-03T10:15:58.608740800Z"
    }
   },
   "id": "b6903a7fd02f6f91"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# I'll take only 10000 samples for measuring this model\n",
    "t5_input = t5_input[:10000]\n",
    "t5_output = t5_output[:10000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T10:25:21.262706500Z",
     "start_time": "2023-11-03T10:25:20.618380600Z"
    }
   },
   "id": "1fe095aceb697f75"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [59:40<00:00,  2.79it/s] \n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "\n",
    "for i, inp in tqdm(enumerate(t5_input), total=len(t5_input)):\n",
    "    pred.append(t5_model.t5_detox(inp))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T11:25:02.635129800Z",
     "start_time": "2023-11-03T10:25:22.091266300Z"
    }
   },
   "id": "e4a81604928226f3"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 8.799947696556991,\n 'counts': [43667, 17456, 8902, 4631],\n 'totals': [166665, 156668, 146689, 136810],\n 'precisions': [26.200462004620046,\n  11.142032833763118,\n  6.068621369018809,\n  3.3849864775966667],\n 'bp': 1.0,\n 'sys_len': 166665,\n 'ref_len': 120861}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure(pred, t5_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T12:12:31.360517400Z",
     "start_time": "2023-11-03T12:12:29.293871100Z"
    }
   },
   "id": "f9f44dab01c3d3cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time to the next model: bart-base-detox"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "946d506a005d093e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "bart_input, bart_output = preprocess_dataset(dataset, bart_base_model.tokenizer, device)\n",
    "bart_input = bart_input[:10000]\n",
    "bart_output = bart_output[:10000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T12:14:48.020774500Z",
     "start_time": "2023-11-03T12:13:28.664142400Z"
    }
   },
   "id": "ca62876dbc36434e"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [44:27<00:00,  3.75it/s] \n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "\n",
    "for i, inp in tqdm(enumerate(bart_input), total=len(t5_input)):\n",
    "    pred.append(bart_base_model.bart_detox(inp))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T12:59:15.813835100Z",
     "start_time": "2023-11-03T12:14:48.024763800Z"
    }
   },
   "id": "e992def94e74f6e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 19.64251856481778,\n 'counts': [63342, 31154, 16738, 8987],\n 'totals': [134353, 124353, 114353, 104372],\n 'precisions': [47.14595133714915,\n  25.052873674137334,\n  14.637132388306384,\n  8.61054688997049],\n 'bp': 1.0,\n 'sys_len': 134353,\n 'ref_len': 120861}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure(pred, bart_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T13:02:25.847163700Z",
     "start_time": "2023-11-03T13:02:24.248008100Z"
    }
   },
   "id": "567a07dc64a86b6f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last model has the best score. So I will use it as my final model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc0a047f2476b91d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
